{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Python\n",
    "## Using BeautifulSoup and Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Classes\n",
    "\n",
    "* We will be using the **selenium** library to control our browser (Chrome)\n",
    "* The **BeautifulSoup (bs4)** library is used to parse and process HTML code. It can also be used for web scraping of simple sites without using selenium.\n",
    "* We use the **time** and **datetime** classes to convert between date strings and the internal representation of dates used by the web site and our database.\n",
    "* The **Stock** and **DailyData** classes are used to store the information about the stocks and price history in our portfolio. They are defined in the stock_class.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "from stock_class import Stock, DailyData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from Yahoo! Finance using Selenium and Beautiful Soup\n",
    "<br/>\n",
    "This code is broken down into two sections. The first uses Selenium to control the browser which will navigate to the web site and retrieve the data. The second part of the code uses BeautifulSoup to process the HTML code, locate the tags of interest, and extract the price and volume data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock price history from web using Web Scraping\n",
    "def retrieve_stock_web(dateStart,dateEnd,stock_list):\n",
    "# Use Selenium to control the browser and retrieve HTML code.\n",
    "    dateFrom = str(int(time.mktime(time.strptime(dateStart,\"%m/%d/%y\"))))\n",
    "    dateTo = str(int(time.mktime(time.strptime(dateEnd,\"%m/%d/%y\"))))\n",
    "    recordCount = 0\n",
    "    for stock in stock_list:\n",
    "        stockSymbol = stock.symbol\n",
    "        url = \"https://finance.yahoo.com/quote/\"+stockSymbol+\"/history?period1=\"+dateFrom+\"&period2=\"+dateTo+\"&interval=1d&filter=history&frequency=1d\"\n",
    "        # Note this code assumes the use of the Chrome browser.\n",
    "        # You will have to modify if you are using a different browser.\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_experimental_option('excludeSwitches',['enable-logging'])\n",
    "        options.add_experimental_option(\"prefs\",{'profile.managed_default_content_settings.javascript': 2})\n",
    "        try:\n",
    "            driver = webdriver.Chrome(options=options)\n",
    "            driver.implicitly_wait(60)\n",
    "            driver.get(url)\n",
    "        except:\n",
    "            raise RuntimeWarning(\"Chrome Driver Not Found\")\n",
    "# Use BeautifulSoup to parse and process HTML code.\n",
    "        soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        row = soup.find('table',class_=\"W(100%) M(0)\")\n",
    "        dataRows = soup.find_all('tr')\n",
    "        for row in dataRows:\n",
    "            td = row.find_all('td')\n",
    "            rowList = [i.text for i in td]\n",
    "            columnCount = len(rowList)\n",
    "            if columnCount == 7: # This row is a standard data row (otherwise it's a special case such as dividend which will be ignored)\n",
    "                daily_data = DailyData(datetime.strptime(rowList[0],\"%b %d, %Y\"),float(rowList[5].replace(',','')),float(rowList[6].replace(',','')))\n",
    "                stock.add_data(daily_data)\n",
    "                recordCount += 1\n",
    "    return recordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Portfolio and Add Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = []\n",
    "stock = Stock('MSFT','Microsoft',100)\n",
    "portfolio.append(stock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call retrieve_stock_web() to Get Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_stock_web('1/1/20','3/1/20',portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in portfolio:\n",
    "    headingLabel = stock.name + \" - \" + str(stock.shares) + \" Shares\\n\"\n",
    "    print(headingLabel)\n",
    "    print(\"- Date -   - Price -   - Volume -\")\n",
    "    print(\"=================================\")\n",
    "    for daily_data in stock.DataList:\n",
    "        row = daily_data.date.strftime(\"%m/%d/%y\") + \"   \" +  '${:0,.2f}'.format(daily_data.close) + \"   \" + str(daily_data.volume)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
